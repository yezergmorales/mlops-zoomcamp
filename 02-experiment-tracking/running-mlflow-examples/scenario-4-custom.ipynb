{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: I work in local but I need my artifacts in a remote S3 bucket.\n",
    "\n",
    "\n",
    "MLflow setup:\n",
    "- tracking server: yes, local server (to see things in real time)\n",
    "- backend store: sqlite database (the metadata is stored here, metrics, tags, and so on...)\n",
    "- artifacts store: s3 bucket (yezer-artifacts-remote-01)\n",
    "\n",
    "To run this example you need to launch the mlflow server locally, store artifacts in s3 bucket by running the following command in your terminal:\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///backend.db --default-artifact-root=s3://yezer-artifacts-remote-01`\n",
    "\n",
    "When you run that MLflow command with an S3 artifact root, AWS authentication happens through one of these methods (in order of precedence):\n",
    "- AWS credentials file (~/.aws/credentials)\n",
    "- Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "- IAM roles (if running on EC2)\n",
    "- AWS CLI configuration (aws configure)\n",
    "\n",
    "I have AWS credentials configured in ~/.aws/credentials with your access key ID and secret access key. This is how MLflow can access your S3 bucket yezer-artifacts-remote-01.\n",
    "\n",
    "The experiments can be explored locally by accessing the local tracking server.\n",
    "\n",
    "this generates a backend.db for the server in the current directory, and the artifacts are stored in the s3 bucket yezer-artifacts-remote-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import pickle as pk\n",
    "from pydantic import BaseModel\n",
    "from typing import Any, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='s3://yezer-artifacts-remote-01/0', creation_time=1750750626480, experiment_id='0', last_update_time=1750750626480, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/24 08:54:07 INFO mlflow.tracking.fluent: Experiment with name 'NYC-taxi-duration-prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='s3://yezer-artifacts-remote-01/1', creation_time=1750751647033, experiment_id='1', last_update_time=1750751647033, lifecycle_stage='active', name='NYC-taxi-duration-prediction', tags={}>,\n",
       " <Experiment: artifact_location='s3://yezer-artifacts-remote-01/0', creation_time=1750750626480, experiment_id='0', last_update_time=1750750626480, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"NYC-taxi-duration-prediction\")\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train & register some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('/home/yezer/projects/mlops-zoomcamp/01-intro/data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('/home/yezer/projects/mlops-zoomcamp/01-intro/data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']\n",
    "\n",
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 's3://yezer-artifacts-remote-01/1/4aa11a9110c34841851c4f32a5e506cf/artifacts'\n",
      "🏃 View run peaceful-sow-991 at: http://127.0.0.1:5000/#/experiments/1/runs/4aa11a9110c34841851c4f32a5e506cf\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    lr = LinearRegression(fit_intercept=True)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    with open('./models/lin_reg.bin', 'wb') as f_out:\n",
    "        pk.dump((lr, dv), f_out)\n",
    "    \n",
    "    mlflow.log_artifact(local_path=\"./models/lin_reg.bin\", artifact_path=\"models\")\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a model from run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ride(BaseModel):  # type: ignore\n",
    "    PULocationID: str\n",
    "    DOLocationID: str\n",
    "    trip_distance: float\n",
    "\n",
    "def prepare_features(ride: Ride) -> Dict[str, Any]:\n",
    "    print(ride)\n",
    "    features: Dict[str, Any] = {}\n",
    "    features['PU_DO'] = f'{ride[\"PULocationID\"]}_{ride[\"DOLocationID\"]}'\n",
    "    features['trip_distance'] = ride[\"trip_distance\"]\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(features: Dict[str, Any], model: Any, dv: Any) -> float:\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download artifact from URI: runs:/4aa11a9110c34841851c4f32a5e506cf/models/lin_reg.bin\n",
      "Artifact downloaded to: /tmp/tmpjb6x_tdz/lin_reg.bin\n",
      "{'PULocationID': '10', 'DOLocationID': '50', 'trip_distance': 10}\n",
      "{'PU_DO': '10_50', 'trip_distance': 10}\n",
      "25.819684421746068\n"
     ]
    }
   ],
   "source": [
    "RUN_ID = \"4aa11a9110c34841851c4f32a5e506cf\"\n",
    "ARTIFACT_FILE_PATH = \"models/lin_reg.bin\"\n",
    "\n",
    "# Construct the URI to the specific artifact file\n",
    "artifact_uri = f\"runs:/{RUN_ID}/{ARTIFACT_FILE_PATH}\"\n",
    "print(f\"Attempting to download artifact from URI: {artifact_uri}\")\n",
    "\n",
    "# Download the artifact.\n",
    "downloaded_artifact_path = mlflow.artifacts.download_artifacts(artifact_uri=artifact_uri)\n",
    "print(f\"Artifact downloaded to: {downloaded_artifact_path}\")\n",
    "\n",
    "# Load the model and DictVectorizer from the downloaded pickle file.\n",
    "with open(downloaded_artifact_path, 'rb') as f_in:\n",
    "    # Unpack the tuple\n",
    "    loaded_model_from_pickle, loaded_dv_from_pickle = pk.load(f_in)\n",
    "\n",
    "ride = {\n",
    "    \"PULocationID\": \"10\",\n",
    "    \"DOLocationID\": \"50\",\n",
    "    \"trip_distance\": 10\n",
    "}\n",
    "\n",
    "features = prepare_features(ride)\n",
    "print(features)\n",
    "\n",
    "preds = predict(features, loaded_model_from_pickle, loaded_dv_from_pickle)\n",
    "\n",
    "print(preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
